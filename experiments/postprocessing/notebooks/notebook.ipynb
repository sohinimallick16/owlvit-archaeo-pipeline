{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d6f6f7b",
   "metadata": {},
   "source": [
    "# Post-Processing Experiment\n",
    "\n",
    "Apply non-maximum suppression (NMS), area filtering, and Top-K selection to prune raw OWL-ViT detections down to a small set of high-quality archaeological features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985df207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().resolve().parents[2]\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from tools.owlvit_utils     import OwlViTPipeline\n",
    "from tools.postprocess_utils import PostprocessUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecbf180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration\n",
    "experiment_name      = 'postprocessing'\n",
    "image_filename       = '<input_image_filename>'  # e.g., 'site_image.png'\n",
    "prompts_file         = '<prompts_file>'          # e.g., 'prompts.txt'\n",
    "resize_size          = (<width>, <height>)       # e.g., (1024, 1024)\n",
    "thresholds           = [<threshold_1>, <threshold_2>, <threshold_3>, <threshold_4>]  # e.g., [0.001, 0.002, ...]\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = OwlViTPipeline(\n",
    "    experiment_name=experiment_name,\n",
    "    resize_size=resize_size\n",
    ")\n",
    "pipeline.load_image(image_filename)\n",
    "pipeline.load_prompts(prompts_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe173f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-shot full-image inference\n",
    "inputs = pipeline.processor(\n",
    "    text=pipeline.prompts,\n",
    "    images=pipeline.image_resized,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "with torch.no_grad():\n",
    "    outputs = pipeline.model(**inputs)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    raw_results = pipeline.processor.post_process_object_detection(\n",
    "        outputs,\n",
    "        target_sizes=torch.tensor([[pipeline.image_full.height,\n",
    "                                    pipeline.image_full.width]]),\n",
    "        threshold=thresh\n",
    "    )[0]\n",
    "    \n",
    "    print(f\"--- Threshold = {thresh:.4f} ---\")\n",
    "\n",
    "    print(f\"Raw detections at t={thresh}: {len(raw_results['scores'])}\")\n",
    "    \n",
    "    # A) Filter to a specific prompt\n",
    "    target_prompt = \"<single_prompt>\"\n",
    "    filt1 = PostprocessUtils.filter_by_prompt(\n",
    "        raw_results,\n",
    "        prompt=target_prompt,\n",
    "        prompts=pipeline.prompts\n",
    "    )\n",
    "    print(\"After prompt filter:\", len(filt1['scores']))\n",
    "\n",
    "    # B) NMS to collapse overlaps\n",
    "    nmsed = PostprocessUtils.apply_nms(filt1, iou_threshold=0.3)\n",
    "    print(\"After NMS:\", len(nmsed['scores']))\n",
    "\n",
    "    # C) Area-based filter (0.005%â€“5% of image area)\n",
    "    areaed = PostprocessUtils.area_filter(\n",
    "        nmsed,\n",
    "        min_pct=0.00005,\n",
    "        max_pct=0.05,\n",
    "        image_size=(pipeline.image_full.width, pipeline.image_full.height)\n",
    "    )\n",
    "    print(\"After area filter:\", len(areaed['scores']))\n",
    "\n",
    "    # D) Top-K to pick the strongest boxes (e.g. K=12)\n",
    "    final = PostprocessUtils.top_k(areaed, k=12)\n",
    "    print(\"After top-K:\", len(final['scores']))\n",
    "    \n",
    "        # Visual check\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.imshow(final)\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Override pipeline.image_resized with preprocessed image\n",
    "    pipeline.image_resized = final.resize(pipeline.resize_size)\n",
    "    \n",
    "    # Save the overlaid detection PNG\n",
    "    png_path = pipeline.save_visualisation(\n",
    "            final,\n",
    "            threshold=thresh\n",
    "            \n",
    "    ) \n",
    "    \n",
    "    # Save the per-threshold metrics JSON\n",
    "    json_path = pipeline.save_metrics(\n",
    "        results,\n",
    "        threshold=thresh,\n",
    "        suffix='tiling'\n",
    "    )\n",
    "    print(\"Saved metrics to:\", json_path)\n",
    "    \n",
    "    # save geojson\n",
    "    geojson_path = pipeline.run_and_save_geojson(thresh)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "owlvit-archaeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
